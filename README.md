# Secure-Deep-Learning
This repository contains code that implements secure deep learning models robust to adversarial samples

## The models folder
This folder contains the different models that we built during the project. We tried different architectures to check which were 
more resilient to adversarial attacks

## The defenses folder
This folder contains the defense mechanisms we
used to defend the models stored in `models` folder against selected adversarial attacks.

## The attacks folder
This folder contains the different attack strategies that we launched to the different models stored in the `models` folder.